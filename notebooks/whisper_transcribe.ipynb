{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from open_whisper import (\n",
    "    load_audio,\n",
    "    log_mel_spectrogram,\n",
    "    pad_or_trim,\n",
    "    load_model,\n",
    "    decoding,\n",
    "    transcribe,\n",
    ")\n",
    "from whisper import whisper"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = torch.device(\"cuda\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "fp = \"checkpoints/whisper/tiny-en-whisper.pt\"\n",
    "model = load_model(fp, device=device, inference=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-3): 4 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51864, 384)\n",
       "    (blocks): ModuleList(\n",
       "      (0-3): 4 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "transcribe.transcribe(\n",
    "    model,\n",
    "    \"data/eval/test-clean-librispeech/test-clean/1089/134686/1089-134686-0000.flac\",\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'text': ' He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out and thick peppered flower-fattened sauce.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 5.5600000000000005,\n",
       "   'text': ' He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat',\n",
       "   'tokens': [50363,\n",
       "    679,\n",
       "    10719,\n",
       "    612,\n",
       "    561,\n",
       "    307,\n",
       "    20798,\n",
       "    329,\n",
       "    8073,\n",
       "    11,\n",
       "    1210,\n",
       "    2419,\n",
       "    290,\n",
       "    34397,\n",
       "    290,\n",
       "    44379,\n",
       "    18821,\n",
       "    290,\n",
       "    3735,\n",
       "    50641],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.304129577818371,\n",
       "   'compression_ratio': 1.361344537815126,\n",
       "   'no_speech_prob': 0.029972951859235764},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 5.5600000000000005,\n",
       "   'end': 10.16,\n",
       "   'text': ' mutton pieces to be ladled out and thick peppered flower-fattened sauce.',\n",
       "   'tokens': [50641,\n",
       "    4517,\n",
       "    1122,\n",
       "    5207,\n",
       "    284,\n",
       "    307,\n",
       "    9717,\n",
       "    992,\n",
       "    503,\n",
       "    290,\n",
       "    6546,\n",
       "    49038,\n",
       "    1068,\n",
       "    15061,\n",
       "    12,\n",
       "    69,\n",
       "    1078,\n",
       "    2945,\n",
       "    10746,\n",
       "    13,\n",
       "    50871],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.304129577818371,\n",
       "   'compression_ratio': 1.361344537815126,\n",
       "   'no_speech_prob': 0.029972951859235764}],\n",
       " 'language': 'en'}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "fp = \"checkpoints/archive/sunny-tree-79/tiny-en-non-ddp_tiny-en_ddp-train_grad-acc_fp16_subset=full_lr=0.0015_batch_size=8_workers=18_epochs=25_train_val_split=0.99_inf.pt\"\n",
    "model = load_model(fp, device=device, inference=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-3): 4 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51864, 384)\n",
       "    (blocks): ModuleList(\n",
       "      (0-3): 4 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "transcribe.transcribe(\n",
    "    model,\n",
    "    \"data/eval/test-clean-librispeech/test-clean/1089/134686/1089-134686-0000.flac\",\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'text': 'he hoped there would be stoover dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out and thick peppercered flower fat and sauce',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 0.66,\n",
       "   'text': 'he hoped there would be stoover dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out and thick peppercered flower fat and sauce',\n",
       "   'tokens': [50396,\n",
       "    258,\n",
       "    10719,\n",
       "    612,\n",
       "    561,\n",
       "    307,\n",
       "    336,\n",
       "    2238,\n",
       "    332,\n",
       "    8073,\n",
       "    1210,\n",
       "    2419,\n",
       "    290,\n",
       "    34397,\n",
       "    290,\n",
       "    44379,\n",
       "    18821,\n",
       "    290,\n",
       "    3735,\n",
       "    4517,\n",
       "    1122,\n",
       "    5207,\n",
       "    284,\n",
       "    307,\n",
       "    9717,\n",
       "    992,\n",
       "    503,\n",
       "    290,\n",
       "    6546,\n",
       "    613,\n",
       "    39921,\n",
       "    1068,\n",
       "    15061,\n",
       "    3735,\n",
       "    290,\n",
       "    10746],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3828220625181456,\n",
       "   'compression_ratio': 1.4375,\n",
       "   'no_speech_prob': 1.245643375114014e-07}],\n",
       " 'language': 'en'}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}