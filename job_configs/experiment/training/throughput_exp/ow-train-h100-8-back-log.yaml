version: v2
budget: ai2/prior
description: training ow small test (backward pass logging)
tasks:
  - name: ow_train_test_back_log
    image:
      beaker: huongn/ow_test_back_log
    command: ['/bin/bash', '-c']
    arguments: ['torchrun --nnodes 1 --nproc_per_node 8 scripts/training/train_wds_no_gradacc.py
      --model_variant=tiny
      --exp_name=ow_tiny_wds
      --job_type=train
      --train_shards=/wds_shards/\{000000..000007\}.tar
      --train_steps=1048576
      --val_shards=/wds_shards/073468.tar
      --run_id=None
      --ckpt_file_name=None
      --log_dir=/data/huongn/ow_logs
      --eval_dir=/ow_eval
      --rank=None
      --world_size=None
      --lr=1.5e-3
      --betas="(0.9, 0.98)"
      --eps=1e-6
      --weight_decay=0.1
      --max_grad_norm=1.0
      --eff_batch_size=64
      --train_batch_size=8
      --val_batch_size=8
      --eval_batch_size=8
      --num_workers=8
      --pin_memory=True
      --persistent_workers=True
      --run_val=False
      --run_eval=False']
    datasets:
    - mountPath: /wds_shards
      source:
        beaker: huongn/mini-job-ow-dataset
    - mountPath: /ow_eval
      source:
        beaker: huongn/mini-job-ow-evalset
    result:
      # Beaker will capture anything that's written to this location and store it in the results
      # dataset. This location is required to be a directory, not a file.
      path: /data/huongn/ow_logs
    envVars:
    - name: PYTHONPATH
      value: /stage
    - name: WANDB_API_KEY
      secret: WANDB_API_KEY
    - name: WANDB_DIR
      value: /data/huongn/ow_logs
    - name: TORCH_NCCL_BLOCKING_WAIT
      value: 1
    - name: TORCH_NCCL_ASYNC_ERROR_HANDLING
      value: 1
    - name: NCCL_DEBUG
      value: INFO
    resources:
      cpuCount: 64
      gpuCount: 8
      memory: 20GiB
    context:
      priority: normal
      preemptible: True
    constraints:
      cluster: [ ai2/jupiter-cirrascale-2 ]