version: v2
budget: ai2/prior
description: filtering experiment with no lower, upper casing and empty transcripts (proxy for identifying machine generated transcripts)
tasks:
  - name: no_lower_upper_empty_mach_gen
    image:
      beaker: huongn/ow_train_no_lower
    command: ['/bin/bash', '-c']
    arguments: ['torchrun --nnodes 1 --nproc_per_node 8 scripts/training/train.py
      --model_variant=tiny
      --exp_name=no_lower_mach_gen
      --job_type=train-filtering
      --samples_dicts_dir=/weka/huongn/ow_filtering/transcript_casing
      --train_steps=58594
      --run_id=None
      --ckpt_file_name=None
      --ckpt_dir=/weka/huongn/ow_ckpts
      --log_dir=/data/huongn/ow_logs
      --eval_dir=/ow_eval
      --rank=None
      --world_size=None
      --lr=1.5e-3
      --betas="(0.9, 0.98)"
      --eps=1e-6
      --weight_decay=0.1
      --max_grad_norm=1.0
      --eff_batch_size=256
      --train_batch_size=16
      --val_batch_size=16
      --eval_batch_size=16
      --num_workers=8
      --pin_memory=True
      --persistent_workers=True
      --run_val=True
      --run_eval=False
      --train_txt_log_freq=100
      --train_tbl_log_freq=20
      --val_freq=10
      --eval_freq=5']
    datasets:
    - mountPath: /weka
      source:
        weka: oe-data-default
    - mountPath: /ow_eval
      source:
        beaker: huongn/mini-job-ow-evalset
    result:
      # Beaker will capture anything that's written to this location and store it in the results
      # dataset. This location is required to be a directory, not a file.
      path: /data/huongn/ow_logs
    envVars:
    - name: PYTHONPATH
      value: /stage
    - name: WANDB_API_KEY
      secret: WANDB_API_KEY
    - name: TORCH_NCCL_BLOCKING_WAIT
      value: 1
    - name: TORCH_NCCL_ASYNC_ERROR_HANDLING
      value:
    - name: NCCL_DEBUG
      value: INFO
    resources:
      cpuCount: 64
      gpuCount: 8
    context:
      priority: normal
      preemptible: True
    constraints:
      cluster: [ ai2/jupiter-cirrascale-2 ]